{
  "name": "llm-chatter-server",
  "private": true,
  "version": "0.2.7",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "devDependencies": {
    "vite": "^7.2.2"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.69.0",
    "@google/genai": "^1.29.1",
    "@modelcontextprotocol/sdk": "^1.22.0",
    "@openai/realtime-api-beta": "github:openai/openai-realtime-api-beta",
    "axios": "^1.13.2",
    "bcryptjs": "^3.0.3",
    "body-parser": "^2.1.0",
    "chalk": "^5.6.2",
    "cors": "^2.8.5",
    "dayjs": "^1.11.19",
    "dotenv": "^17.2.3",
    "express": "^5.0.1",
    "express-rate-limit": "^8.2.1",
    "express-validator": "^7.3.0",
    "fs": "^0.0.2",
    "helmet": "^8.1.0",
    "jsonwebtoken": "^9.0.2",
    "mime-types": "^3.0.1",
    "openai": "^6.9.0",
    "path": "^0.12.7",
    "redis": "^5.9.0",
    "ws": "^8.18.1"
  }
}
